{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e",
    "tags": []
   },
   "source": [
    "# Getting Started with Vertex AI Turbo Templates\n",
    "\n",
    "This notebook sets up infrastructure to run production-ready pipelines on Google Cloud. Follow this three-part notebook series to get started in a local Jupyter notebook or in [Vertex AI Workbench](https://cloud.google.com/vertex-ai-notebooks):\n",
    "\n",
    "1. **[Infrastructure Setup](./02_run_pipelines.ipynb) - this notebook**\n",
    "1. [Run Pipelines](./02_run_pipelines.ipynb)\n",
    "1. [Infrastructure Clean Up](./02_run_pipelines.ipynb)\n",
    "\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "- [Google Cloud SDK (gcloud)](https://cloud.google.com/sdk/docs/quickstart)\n",
    "- Make\n",
    "- [Terraform](https://www.terraform.io)\n",
    "\n",
    "**For Vertex AI Workbench users**: \n",
    "Uncomment and execute the following cell to install Terraform.\n",
    "Restart the notebook kernel or the Workbench instance to ensure `terraform` is available in the `PATH`.\n",
    "Then return to this notebook and continue with the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./scripts/install_terraform.sh: line 11: terraform: command not found\n"
     ]
    }
   ],
   "source": [
    "# ! bash ./scripts/install_terraform.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate\n",
    "\n",
    "Set your project ID and authenticate using your Google Account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your active configuration is: [thierry-mlops]\n",
      "uk-gap-proximity-dev\n"
     ]
    }
   ],
   "source": [
    "! gcloud config get-value project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [core/account].\n",
      "Y"
     ]
    }
   ],
   "source": [
    "VERTEX_PROJECT_ID = \"uk-gap-proximity-dev\"\n",
    "GOOGLE_ACCOUNT = \"thierry.dacae@sky.uk\"\n",
    "! gcloud config set project {VERTEX_PROJECT_ID} --quiet\n",
    "! gcloud config set account {GOOGLE_ACCOUNT} --quiet\n",
    "! printf 'Y' gcloud auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Code\n",
    "\n",
    "**If you haven't cloned the template, yet:** Uncomment and execute the following cell to clone the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'vertex-pipelines-end-to-end-samples'...\n",
      "remote: Enumerating objects: 4041, done.\u001b[K\n",
      "remote: Counting objects: 100% (1071/1071), done.\u001b[K\n",
      "remote: Compressing objects: 100% (462/462), done.\u001b[K\n",
      "remote: Total 4041 (delta 699), reused 678 (delta 597), pack-reused 2970\u001b[K\n",
      "Receiving objects: 100% (4041/4041), 3.42 MiB | 24.29 MiB/s, done.\n",
      "Resolving deltas: 100% (2323/2323), done.\n"
     ]
    }
   ],
   "source": [
    "# ! git clone -b develop https://github.com/teamdatatonic/vertex-pipelines-end-to-end-samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to the folder in which the template code is cloned to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/MLOPS Hackathlon/mlops-hackathon/docs/notebooks/vertex-pipelines-end-to-end-samples\n"
     ]
    }
   ],
   "source": [
    "%cd vertex-pipelines-end-to-end-samples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/MLOPS Hackathlon/mlops-hackathon/docs/notebooks/vertex-pipelines-end-to-end-samples'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure your code by setting the variables:\n",
    "- `VERTEX_PROJECT_ID` - as set above\n",
    "- `VERTEX_LOCATION` - location of the cloud project\n",
    "- `BQ_LOCATION` - location of the BigQuery dataset, for this notebook example you can leave this as-is\n",
    "- `RESOURCE_SUFFIX` - suffix (e.g. `<your name>`) to facilitate running concurrent pipelines in the same Google Cloud project. Change if working in a team to avoid overwriting resources during development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting env.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile env.sh\n",
    "#!/bin/bash\n",
    "VERTEX_PROJECT_ID=VERTEX_PROJECT_ID\n",
    "VERTEX_LOCATION=europe-west2\n",
    "BQ_LOCATION=US\n",
    "RESOURCE_SUFFIX=default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most use cases you won't need to change the following variables unless you've modified the Terraform code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to env.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a env.sh\n",
    "# Optional\n",
    "VERTEX_CMEK_IDENTIFIER=\n",
    "VERTEX_NETWORK=\n",
    "# Leave as-is\n",
    "VERTEX_SA_EMAIL=vertex-pipelines@${VERTEX_PROJECT_ID}.iam.gserviceaccount.com\n",
    "VERTEX_PIPELINE_ROOT=gs://${VERTEX_PROJECT_ID}-pl-root\n",
    "CONTAINER_IMAGE_REGISTRY=${VERTEX_LOCATION}-docker.pkg.dev/${VERTEX_PROJECT_ID}/vertex-images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk",
    "tags": []
   },
   "source": [
    "## Deploy Infrastructure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cloud infrastructure is managed using Terraform and is defined in the [`terraform`](terraform) directory. There are three Terraform modules defined in [`terraform/modules`](terraform/modules):\n",
    "\n",
    "- `cloudfunction` - deploys a (Pub/Sub-triggered) Cloud Function from local source code\n",
    "- `scheduled_pipelines` - deploys Cloud Scheduler jobs that will trigger Vertex Pipeline runs (via the above Cloud Function)\n",
    "- `vertex_deployment` - deploys Cloud infrastructure required for running Vertex Pipelines, including enabling APIs, creating buckets, Artifact Registry repos, service accounts, and IAM permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enable APIs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gcloud auth login --quiet\n",
    "\n",
    "# td: run in terminal and copy and paste access code:\n",
    "gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation \"operations/acat.p2-213412891337-f63f28f4-49b0-4e01-8492-b58d194498bc\" finished successfully.\n"
     ]
    }
   ],
   "source": [
    "! gcloud services enable cloudresourcemanager.googleapis.com serviceusage.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uk-gap-proximity-dev'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VERTEX_PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERTEX_LOCATION = \"europe-west2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Cloud Storage bucket:**\n",
    "\n",
    "Store the [Terraform state files](https://developer.hashicorp.com/terraform/language/state/remote) in the bucket `[project-id]-tfstate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NIq7R4HZCfIc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://uk-gap-proximity-dev-tfstate/...\n"
     ]
    }
   ],
   "source": [
    "! source env.sh && gsutil mb -l $VERTEX_LOCATION -p $VERTEX_PROJECT_ID gs://$VERTEX_PROJECT_ID-tfstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTerraform initialized in an empty directory!\u001b[0m\n",
      "\n",
      "The directory has no Terraform configuration files. You may begin working\n",
      "with Terraform immediately by creating Terraform configuration files.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !terraform init -reconfigure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run in terminal:\n",
    "# gcloud auth application-default login --project uk-gap-proximity-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://artifacts.uk-gap-proximity-dev.appspot.com/\n",
      "gs://cdn-logs-config-dev/\n",
      "gs://cdn-suspicious-asn-dev/\n",
      "gs://cdn_logs_test/\n",
      "gs://cloud-ai-platform-6e01d309-9443-4e6e-a71b-b118006bee93/\n",
      "gs://cloud-ai-platform-7f322054-1127-4f3f-a8b6-a013fa86c892/\n",
      "gs://cloud_logger_test/\n",
      "gs://dataflow-staging-europe-west1-4b5ff1d7df0f5e4dab4a63d14ebc9c75/\n",
      "gs://eu.artifacts.uk-gap-proximity-dev.appspot.com/\n",
      "gs://europe-west1-uk-gap-proximi-11d508c9-bucket/\n",
      "gs://europe-west1-uk-gap-proximi-4af96600-bucket/\n",
      "gs://europe-west1-uk-gap-proximi-4ee0444f-bucket/\n",
      "gs://europe-west1-uk-gap-proximi-586a4af1-bucket/\n",
      "gs://europe-west1-uk-gap-proximi-65e5278a-bucket/\n",
      "gs://europe-west1-uk-gap-proximi-9f3b269c-bucket/\n",
      "gs://europe-west1-uk-gap-proximi-b8fa634c-bucket/\n",
      "gs://europe-west1-uk-gap-proximi-f5236786-bucket/\n",
      "gs://europe-west1-uk-gap-proximi-fbf9c379-bucket/\n",
      "gs://gcf-sources-213412891337-europe-west2/\n",
      "gs://gcf-v2-sources-213412891337-europe-west1/\n",
      "gs://gcf-v2-sources-213412891337-europe-west2/\n",
      "gs://gcf-v2-sources-213412891337-us-central1/\n",
      "gs://gcf-v2-uploads-213412891337-europe-west1/\n",
      "gs://gcf-v2-uploads-213412891337-europe-west2/\n",
      "gs://gcf-v2-uploads-213412891337-us-central1/\n",
      "gs://logan-lab-bucket/\n",
      "gs://mlops-mlops/\n",
      "gs://sky-mlops-dev/\n",
      "gs://ua-parser-demo-bucket/\n",
      "gs://uk-gap-proximity-dev-eu-notebooks/\n",
      "gs://uk-gap-proximity-dev-tfstate/\n",
      "gs://uk-gap-proximity-dev_cloudbuild/\n",
      "gs://uk-gap-proximity-testing-bucket-dev/\n",
      "gs://uk-gap-proximity-tf-state-dev/\n"
     ]
    }
   ],
   "source": [
    "!gcloud storage ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Deploy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "# Deploy dev environment\n",
      "################################################################################\n",
      "\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
      "\u001b[0m\u001b[1mInitializing modules...\u001b[0m\n",
      "\u001b[31m\u001b[31m╷\u001b[0m\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[0m\u001b[1m\u001b[31mError: \u001b[0m\u001b[0m\u001b[1mFailed to get existing workspaces: querying Cloud Storage failed: storage: bucket doesn't exist\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[0m\u001b[0m\n",
      "\u001b[31m╵\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "make: *** [Makefile:25: deploy] Error 1\n"
     ]
    }
   ],
   "source": [
    "! make deploy auto-approve=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've successfully deployed a `dev` environment! 🎉 \n",
    "Continue with [this notebook](./02_run_pipelines.ipynb) to run your first Vertex AI Pipelines in the deployed project.\n",
    "\n",
    "**Note:** If you'd like to deploy separate cloud environments as shown below, try out `make deploy env=dev` where you can replace `dev` with `test` or `prod`.\n",
    "\n",
    "**Troubleshooting:** If enabling of APIs or the deployment fails, check whether your Google user account has the appropriate permissions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m116"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb5c7b0035bb37e2e2e56e6840dfdd8f7fa070884ae8e041fbcae450545b1006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
